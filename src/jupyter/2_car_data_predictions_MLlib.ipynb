{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c207511-0fe4-4633-9124-a5c3fe025b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1)\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.linalg import Vectors, SparseVector\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import VectorUDT\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.pipeline import PipelineModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a1a112-53c6-4cc9-9b71-16857bc2d16d",
   "metadata": {},
   "source": [
    "# Start Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812212bf-65bd-488d-a5c1-dea4ec3550a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(2)\n",
    "# Start spark session. \n",
    "\n",
    "spark = SparkSession\\\n",
    "            .builder\\\n",
    "            .master(\"spark://spark-master:7077\")\\\n",
    "            .appName(\"2_car_data_predictions_MLlib_jupyter\")\\\n",
    "            .config(\"spark.executor.memory\", \"3G\")\\\n",
    "            .config(\"spark.driver.memory\", \"3G\")\\\n",
    "            .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\\\n",
    "            .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c29feba-ff38-4676-af6c-7baccd98a0dd",
   "metadata": {},
   "source": [
    "# Load the Pre-processed Car Data Parquet File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865507a3-0400-48b9-84d8-3a7afaca1f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(3)\n",
    "# Read in Parquet file.\n",
    "\n",
    "car_df = spark.read.parquet(\"/data/car_data.parquet\")\n",
    "\n",
    "car_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174cbcd0-7e45-45fb-bb4a-de348f8a6d21",
   "metadata": {},
   "source": [
    "# Prepare Data for Algorithmic Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132928f4-8f61-4212-a33d-a59ef9fb09e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(4)\n",
    "# Map a string column of labels to an ML column of label indices \n",
    "\n",
    "# (Colums : 'Fuel_Type', 'Seller_Type', 'Transmission').\n",
    "\n",
    "\n",
    "car_df = car_df.drop('fuel_Type_idx', 'seller_type_idx', 'transmission_idx')\n",
    "\n",
    "indexer = StringIndexer(inputCols=['Fuel_Type', 'Seller_Type', 'Transmission'],\n",
    "                        outputCols=['fuel_Type_idx', 'seller_type_idx', 'transmission_idx']\n",
    ")\n",
    "\n",
    "car_df = indexer.fit(car_df).transform(car_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763d3d8d-fa2c-41d1-bf06-2d4adc1d31ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(5)\n",
    "# We created 3 new columns. Show aggregate counts.\n",
    "\n",
    "car_df.select('Fuel_Type','fuel_Type_idx')\\\n",
    "    .groupBy('Fuel_Type','fuel_Type_idx')\\\n",
    "    .count()\\\n",
    "    .orderBy(F.col('fuel_Type_idx').asc())\\\n",
    "    .show()\n",
    "\n",
    "car_df.select('Seller_Type','seller_type_idx')\\\n",
    "    .groupBy('Seller_Type','seller_type_idx')\\\n",
    "    .count()\\\n",
    "    .orderBy(F.col('seller_type_idx').asc())\\\n",
    "    .show()\n",
    "\n",
    "car_df.select('Transmission','transmission_idx')\\\n",
    "    .groupBy('Transmission','transmission_idx')\\\n",
    "    .count()\\\n",
    "    .orderBy(F.col('transmission_idx').asc())\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db876bcb-a88a-4f4e-a342-57221aaf885f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(6)\n",
    "# The car_df dataframe will show the 3 extra columns : 'fuel_Type_idx', 'seller_type_idx', 'transmission_idx'\n",
    "\n",
    "car_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b236d96f-f3b4-40bb-8a49-8d1c3c3ecab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(7)\n",
    "# One-hot encoding. \n",
    "\n",
    "# Drop the columns I'm just about to create if they exist.\n",
    "car_df = car_df.drop('fuel_Type_vec', 'seller_type_vec', 'transmission_vec')\n",
    "\n",
    "encoder = OneHotEncoder(inputCols=['fuel_Type_idx', 'seller_type_idx', 'transmission_idx'],\n",
    "                        outputCols=['fuel_Type_vec', 'seller_type_vec', 'transmission_vec'],\n",
    "                        dropLast=False\n",
    ")\n",
    "model = encoder.fit(car_df)\n",
    "car_df = model.transform(car_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32a4074-6539-48bf-9128-40a88eed26dc",
   "metadata": {},
   "source": [
    "# Visual One Hot encoding ? \n",
    "\n",
    "<img src=\"media/one_hot.png\" alt=\"one_hot\" width=\"800\"/>\n",
    "\n",
    "Image Source : https://medium.com/@michaeldelsole/what-is-one-hot-encoding-and-how-to-do-it-f0ae272f1179"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac88d45-edf1-4ea0-b875-b1fc6aaf1413",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(8)\n",
    "\n",
    "# https://spark.apache.org/docs/latest/ml-features.html#vectorassembler\n",
    "\n",
    "# Reminder... sparse vector (size, [non-zero indices], [non-zero values]) \n",
    "# [1.0, 0.0, 0.0] = (3,[0],[1.0]) - > (vector of size 3, [index 0], [gets value 1.0])\n",
    "\n",
    "car_df\\\n",
    "    .select('Fuel_type', 'fuel_type_idx', 'fuel_type_vec')\\\n",
    "    .distinct()\\\n",
    "    .show()\n",
    "\n",
    "car_df\\\n",
    "    .select('Seller_type', 'seller_type_idx', 'seller_type_vec')\\\n",
    "    .distinct()\\\n",
    "    .show()\n",
    "\n",
    "car_df\\\n",
    "    .select('Transmission', 'transmission_idx', 'transmission_vec')\\\n",
    "    .distinct()\\\n",
    "    .show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3da80d-1701-4d44-bb65-058d3b2c47ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(9)\n",
    "# Print the car_df schema. \n",
    "\n",
    "# The car_df dataframe will show the 3 extra columns : 'fuel_Type_vec', 'seller_type_vec', 'transmission_vec'\n",
    "\n",
    "car_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7e8dd4-907f-4fe2-bd7d-7e4d01d9d5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(10)\n",
    "# Drop the column if exists\n",
    "car_df = car_df.drop('algorithmic_input')\n",
    "\n",
    "\n",
    "# Assemble features I'm interested in using as a large vector column called 'algorithmic_input'.\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\n",
    "        'Present_Price', \n",
    "        'Kms_Driven', \n",
    "        'Owner', \n",
    "        'Car_Age', \n",
    "        'fuel_Type_vec', \n",
    "        'seller_type_vec',\n",
    "        'transmission_vec'\n",
    "    ],\n",
    "    outputCol='algorithmic_input')\n",
    "\n",
    "\n",
    "car_df = assembler.transform(car_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca1cc86-8e8f-4af0-b6b6-49c94ca4a2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(11)\n",
    "# Print the car_df schema. \n",
    "\n",
    "# The car_df dataframe will show the 1 extra columns : 'algorithmic_input'\n",
    "\n",
    "car_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918014d0-b50a-46d1-a4f7-7ffcec903c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(12)\n",
    "# Show the some of the table columns\n",
    "\n",
    "car_df.select('algorithmic_input', 'Selling_Price').show(5, False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25713e58-1a13-4a93-a3a6-2af5a2fc8193",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52917ba-fc9e-458d-bcd3-bd2216804565",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(13)\n",
    "# Create train/test split. Seed it for reproducibility.\n",
    "seed = 111\n",
    "train_df, test_df = car_df.randomSplit([0.7, 0.3], seed=seed)\n",
    "\n",
    "print('Training Dataset Count : {}'.format(train_df.count()))\n",
    "print('Test Dataset Count : {}'.format(test_df.count()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20c5197-9486-4509-b6ca-5a1fb1860349",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(14)\n",
    "# Train a simlpe RandomForestRegressor model. This very simple model is meant \n",
    "# to show model feature inputs and outputs. The model is kept simple on purpose \n",
    "# to keep training time short.\n",
    "\n",
    "\n",
    "# For more information on model tuning and ParamGrid, \n",
    "# this is a good resource to start with : https://medium.com/rahasak/random-forest-classifier-with-apache-spark-c63b4a23a7cc\n",
    "\n",
    "# Instantiate RandomForestRegressor class\n",
    "rf = RandomForestRegressor(featuresCol='algorithmic_input', \n",
    "                           labelCol='Selling_Price'\n",
    ")\n",
    "\n",
    "# Set some parameters ...\n",
    "#\n",
    "# numTrees : Number of trees in the random forest.\n",
    "# maxDepth : Maximum depth of a tree. Increasing the depth makes the model more powerful, but deep trees take longer to train.\n",
    "# impurity : Criterion used for information gain calculation\n",
    "# setFeatureSubsetStrategy : auto -> Automatically select the number of features to consider for splits at each tree node\n",
    "# seed : Use a random seed number , allowing to repeat the results\n",
    "\n",
    "rf.setNumTrees(200)\n",
    "rf.setMaxDepth(20)\n",
    "rf.setImpurity(\"variance\")\n",
    "rf.setFeatureSubsetStrategy(\"auto\")\n",
    "rf.setSeed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31139a0c-5e41-4da2-9b44-2d7c531892ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(15)\n",
    "# Chain rf model in a Pipeline. Could have included previous steps above (indexer, encoder, assembler) ...\n",
    "pipeline = Pipeline(stages=[rf])\n",
    "\n",
    "# Train model\n",
    "model = pipeline.fit(train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e46720-1402-4d8d-9476-9f873327fdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(16)\n",
    "# Make predictions.\n",
    "\n",
    "predictions = model.transform(test_df)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"algorithmic_input\", \"prediction\", \"Selling_Price\").show(5, False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efe9833-d9d4-4030-9d1b-af60bd71a782",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36f02c3-f79b-4cf6-9df0-c16ff8074dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(17)\n",
    "# Evaluate Model.\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(labelCol=\"Selling_Price\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"Selling_Price\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "r2 = evaluator.evaluate(predictions)\n",
    "print(\"R Squared (R2) on test data = %g\" % r2)\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"Selling_Price\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "mae = evaluator.evaluate(predictions)\n",
    "print(\"Mean Absolute Error (MAE) on test data = %g\" % mae)\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"Selling_Price\", predictionCol=\"prediction\", metricName=\"mse\")\n",
    "mse = evaluator.evaluate(predictions)\n",
    "print(\"Mean Square Error (MSE) on test data = %g\" % mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3668c1c6-c979-445b-a0a4-92b12dc6fe5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(18)\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c68eb2b-5043-4471-b52c-1ecaf261b9b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
