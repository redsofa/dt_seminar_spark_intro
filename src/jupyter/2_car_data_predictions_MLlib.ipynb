{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c207511-0fe4-4633-9124-a5c3fe025b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.linalg import Vectors, SparseVector\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import VectorUDT\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.pipeline import PipelineModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a1a112-53c6-4cc9-9b71-16857bc2d16d",
   "metadata": {},
   "source": [
    "# Start Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "812212bf-65bd-488d-a5c1-dea4ec3550a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/03/31 16:16:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Start spark session. \n",
    "\n",
    "spark = SparkSession\\\n",
    "            .builder\\\n",
    "            .master(\"spark://spark-master:7077\")\\\n",
    "            .appName(\"2_car_data_predictions_MLlib_jupyter\")\\\n",
    "            .config(\"spark.executor.memory\", \"3G\")\\\n",
    "            .config(\"spark.driver.memory\", \"3G\")\\\n",
    "            .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c29feba-ff38-4676-af6c-7baccd98a0dd",
   "metadata": {},
   "source": [
    "# Load the Pre-processed Car Data Parquet File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "865507a3-0400-48b9-84d8-3a7afaca1f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Read in Parquet file.\n",
    "\n",
    "car_df = spark.read.parquet(\"/data/car_data.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8623d387-10c3-4bc4-b5da-b557b8ec3149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Car_Name: string (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Selling_Price: double (nullable = true)\n",
      " |-- Present_Price: double (nullable = true)\n",
      " |-- Kms_Driven: integer (nullable = true)\n",
      " |-- Fuel_Type: string (nullable = true)\n",
      " |-- Seller_Type: string (nullable = true)\n",
      " |-- Transmission: string (nullable = true)\n",
      " |-- Owner: integer (nullable = true)\n",
      " |-- Car_Age: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the dataframe schema.\n",
    "\n",
    "car_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3334550-1c32-4b26-810f-54648b259ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+----+-------------+-------------+----------+---------+-----------+------------+-----+-------+\n",
      "|Car_Name              |Year|Selling_Price|Present_Price|Kms_Driven|Fuel_Type|Seller_Type|Transmission|Owner|Car_Age|\n",
      "+----------------------+----+-------------+-------------+----------+---------+-----------+------------+-----+-------+\n",
      "|ertiga                |2014|6.0          |9.95         |45000     |Diesel   |Dealer     |Manual      |0    |8      |\n",
      "|city                  |2015|8.4          |13.6         |34000     |Petrol   |Dealer     |Manual      |0    |7      |\n",
      "|TVS Apache RTR 160    |2012|0.6          |0.81         |19000     |Petrol   |Individual |Manual      |0    |10     |\n",
      "|etios liva            |2011|2.65         |5.71         |43000     |Petrol   |Dealer     |Manual      |0    |11     |\n",
      "|Hero Honda Passion Pro|2012|0.3          |0.51         |60000     |Petrol   |Individual |Manual      |0    |10     |\n",
      "+----------------------+----+-------------+-------------+----------+---------+-----------+------------+-----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Show a few sample records. \n",
    "\n",
    "car_df.show(5, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "425544e0-7e82-43a2-9f37-5d852eaf83e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:===================>                                       (2 + 4) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|partitionId|count|\n",
      "+-----------+-----+\n",
      "|          2|   50|\n",
      "|          4|   50|\n",
      "|          0|   50|\n",
      "|          3|   50|\n",
      "|          5|   50|\n",
      "|          1|   51|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# What's the partitioning situation in the Parquet file ?\n",
    "\n",
    "car_df\\\n",
    "    .withColumn(\"partitionId\", F.spark_partition_id())\\\n",
    "    .groupBy(\"partitionId\")\\\n",
    "    .count()\\\n",
    "    .orderBy(F.asc(\"count\"))\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174cbcd0-7e45-45fb-bb4a-de348f8a6d21",
   "metadata": {},
   "source": [
    "# Prepare Data for Algorithmic Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "132928f4-8f61-4212-a33d-a59ef9fb09e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Map a string column of labels to an ML column of label indices \n",
    "\n",
    "# (Colums : 'Fuel_Type', 'Seller_Type', 'Transmission').\n",
    "\n",
    "\n",
    "car_df = car_df.drop('fuel_Type_idx', 'seller_type_idx', 'transmission_idx')\n",
    "\n",
    "indexer = StringIndexer(inputCols=['Fuel_Type', 'Seller_Type', 'Transmission'],\n",
    "                        outputCols=['fuel_Type_idx', 'seller_type_idx', 'transmission_idx']\n",
    ")\n",
    "\n",
    "car_df = indexer.fit(car_df).transform(car_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "763d3d8d-fa2c-41d1-bf06-2d4adc1d31ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+-----+\n",
      "|Fuel_Type|fuel_Type_idx|count|\n",
      "+---------+-------------+-----+\n",
      "|   Petrol|          0.0|  239|\n",
      "|   Diesel|          1.0|   60|\n",
      "|      CNG|          2.0|    2|\n",
      "+---------+-------------+-----+\n",
      "\n",
      "+-----------+---------------+-----+\n",
      "|Seller_Type|seller_type_idx|count|\n",
      "+-----------+---------------+-----+\n",
      "|     Dealer|            0.0|  195|\n",
      "| Individual|            1.0|  106|\n",
      "+-----------+---------------+-----+\n",
      "\n",
      "+------------+----------------+-----+\n",
      "|Transmission|transmission_idx|count|\n",
      "+------------+----------------+-----+\n",
      "|      Manual|             0.0|  261|\n",
      "|   Automatic|             1.0|   40|\n",
      "+------------+----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We created 3 new columns. Show aggregate counts.\n",
    "\n",
    "car_df.select('Fuel_Type','fuel_Type_idx')\\\n",
    "    .groupBy('Fuel_Type','fuel_Type_idx')\\\n",
    "    .count()\\\n",
    "    .orderBy(F.col('fuel_Type_idx').asc())\\\n",
    "    .show()\n",
    "\n",
    "car_df.select('Seller_Type','seller_type_idx')\\\n",
    "    .groupBy('Seller_Type','seller_type_idx')\\\n",
    "    .count()\\\n",
    "    .orderBy(F.col('seller_type_idx').asc())\\\n",
    "    .show()\n",
    "\n",
    "car_df.select('Transmission','transmission_idx')\\\n",
    "    .groupBy('Transmission','transmission_idx')\\\n",
    "    .count()\\\n",
    "    .orderBy(F.col('transmission_idx').asc())\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db876bcb-a88a-4f4e-a342-57221aaf885f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Car_Name: string (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Selling_Price: double (nullable = true)\n",
      " |-- Present_Price: double (nullable = true)\n",
      " |-- Kms_Driven: integer (nullable = true)\n",
      " |-- Fuel_Type: string (nullable = true)\n",
      " |-- Seller_Type: string (nullable = true)\n",
      " |-- Transmission: string (nullable = true)\n",
      " |-- Owner: integer (nullable = true)\n",
      " |-- Car_Age: integer (nullable = true)\n",
      " |-- fuel_Type_idx: double (nullable = false)\n",
      " |-- seller_type_idx: double (nullable = false)\n",
      " |-- transmission_idx: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The car_df dataframe will show the 3 extra columns : 'fuel_Type_idx', 'seller_type_idx', 'transmission_idx'\n",
    "\n",
    "car_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b236d96f-f3b4-40bb-8a49-8d1c3c3ecab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding. For string type input data, it is common to encode categorical features using StringIndexer first.\n",
    "\n",
    "# Drop the columns I'm just about to create if they exist.\n",
    "car_df = car_df.drop('fuel_Type_vec', 'seller_type_vec', 'transmission_vec')\n",
    "\n",
    "encoder = OneHotEncoder(inputCols=['fuel_Type_idx', 'seller_type_idx', 'transmission_idx'],\n",
    "                        outputCols=['fuel_Type_vec', 'seller_type_vec', 'transmission_vec'],\n",
    "                        dropLast=True\n",
    ")\n",
    "model = encoder.fit(car_df)\n",
    "car_df = model.transform(car_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ac88d45-edf1-4ea0-b875-b1fc6aaf1413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+-------------+\n",
      "|Fuel_type|fuel_type_idx|fuel_type_vec|\n",
      "+---------+-------------+-------------+\n",
      "|   Petrol|          0.0|(2,[0],[1.0])|\n",
      "|   Diesel|          1.0|(2,[1],[1.0])|\n",
      "|      CNG|          2.0|    (2,[],[])|\n",
      "+---------+-------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Something to be aware of ...\n",
    "\n",
    "# PySpark automatically drops the last category is not included BY DEFAULT. This is to avoid a Dummy Variable Trap\n",
    "# linear regression models....\n",
    "\n",
    "# What is the Dummy Variable Trap (DVT)? The DVT occurs when two or more dummy variables \n",
    "# created by one-hot encoding are highly correlated (multi-collinear). This means that one variable can be \n",
    "# predicted from the others, making it difficult to interpret predicted coefficient variables in regression models.\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/39500213/why-does-sparks-onehotencoder-drop-the-last-category-by-default\n",
    "\n",
    "# But basically, ... dropping the last cat. value is done to avoid a DVT where one input variable can be predicted \n",
    "# from the others (eg. don't need a 1hot encoding of [isBoy, isGirl] when an encoding [isBoy] would give the same info). \n",
    "# The solution to the DVT is to drop one (not necessarily the last) of the cat. variables.\n",
    "\n",
    "\n",
    "# There are 3 fuel types but the 'fuel_type_vec' column has only 2 elements because of this DVT last category drop thing.\n",
    "\n",
    "car_df\\\n",
    "    .select('Fuel_type', 'fuel_type_idx', 'fuel_type_vec')\\\n",
    "    .distinct()\\\n",
    "    .show(10)\n",
    "                                                                                                                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d3da80d-1701-4d44-bb65-058d3b2c47ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Car_Name: string (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Selling_Price: double (nullable = true)\n",
      " |-- Present_Price: double (nullable = true)\n",
      " |-- Kms_Driven: integer (nullable = true)\n",
      " |-- Fuel_Type: string (nullable = true)\n",
      " |-- Seller_Type: string (nullable = true)\n",
      " |-- Transmission: string (nullable = true)\n",
      " |-- Owner: integer (nullable = true)\n",
      " |-- Car_Age: integer (nullable = true)\n",
      " |-- fuel_Type_idx: double (nullable = false)\n",
      " |-- seller_type_idx: double (nullable = false)\n",
      " |-- transmission_idx: double (nullable = false)\n",
      " |-- fuel_Type_vec: vector (nullable = true)\n",
      " |-- seller_type_vec: vector (nullable = true)\n",
      " |-- transmission_vec: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the car_df schema. \n",
    "\n",
    "# The car_df dataframe will show the 3 extra columns : 'fuel_Type_vec', 'seller_type_vec', 'transmission_vec'\n",
    "\n",
    "car_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a7e8dd4-907f-4fe2-bd7d-7e4d01d9d5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://spark.apache.org/docs/latest/ml-features.html#vectorassembler\n",
    "\n",
    "# Reminder... sparse vector (size, [non-zero indices], [non-zero values]) \n",
    "# [1.0,0.0] = (2,[0],[1.0])\n",
    "\n",
    "# Drop the column if exists\n",
    "car_df = car_df.drop('algorithmic_input')\n",
    "\n",
    "\n",
    "# Assemble features I'm interested in using as a large vector column called 'algorithmic_input'.\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\n",
    "        'Present_Price', \n",
    "        'Kms_Driven', \n",
    "        'Owner', \n",
    "        'Car_Age', \n",
    "        'fuel_Type_vec', \n",
    "        'seller_type_vec',\n",
    "        'transmission_vec'\n",
    "    ],\n",
    "    outputCol='algorithmic_input')\n",
    "\n",
    "\n",
    "car_df = assembler.transform(car_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ca1cc86-8e8f-4af0-b6b6-49c94ca4a2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Car_Name: string (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Selling_Price: double (nullable = true)\n",
      " |-- Present_Price: double (nullable = true)\n",
      " |-- Kms_Driven: integer (nullable = true)\n",
      " |-- Fuel_Type: string (nullable = true)\n",
      " |-- Seller_Type: string (nullable = true)\n",
      " |-- Transmission: string (nullable = true)\n",
      " |-- Owner: integer (nullable = true)\n",
      " |-- Car_Age: integer (nullable = true)\n",
      " |-- fuel_Type_idx: double (nullable = false)\n",
      " |-- seller_type_idx: double (nullable = false)\n",
      " |-- transmission_idx: double (nullable = false)\n",
      " |-- fuel_Type_vec: vector (nullable = true)\n",
      " |-- seller_type_vec: vector (nullable = true)\n",
      " |-- transmission_vec: vector (nullable = true)\n",
      " |-- algorithmic_input: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the car_df schema. \n",
    "\n",
    "# The car_df dataframe will show the 1 extra columns : 'algorithmic_input'\n",
    "\n",
    "car_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "918014d0-b50a-46d1-a4f7-7ffcec903c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------+-------------+\n",
      "|algorithmic_input                      |Selling_Price|\n",
      "+---------------------------------------+-------------+\n",
      "|[9.95,45000.0,0.0,8.0,0.0,1.0,1.0,1.0] |6.0          |\n",
      "|[13.6,34000.0,0.0,7.0,1.0,0.0,1.0,1.0] |8.4          |\n",
      "|[0.81,19000.0,0.0,10.0,1.0,0.0,0.0,1.0]|0.6          |\n",
      "|[5.71,43000.0,0.0,11.0,1.0,0.0,1.0,1.0]|2.65         |\n",
      "|[0.51,60000.0,0.0,10.0,1.0,0.0,0.0,1.0]|0.3          |\n",
      "|[6.8,33019.0,0.0,8.0,1.0,0.0,1.0,1.0]  |3.75         |\n",
      "|[12.04,15000.0,0.0,8.0,1.0,0.0,1.0,0.0]|7.5          |\n",
      "|[9.9,56701.0,0.0,9.0,1.0,0.0,1.0,1.0]  |5.0          |\n",
      "|[23.15,11000.0,0.0,5.0,1.0,0.0,1.0,0.0]|19.75        |\n",
      "|[0.81,42000.0,0.0,8.0,1.0,0.0,0.0,1.0] |0.42         |\n",
      "+---------------------------------------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the some of the table columns\n",
    "\n",
    "car_df.select('algorithmic_input', 'Selling_Price').show(10, False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25713e58-1a13-4a93-a3a6-2af5a2fc8193",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e52917ba-fc9e-458d-bcd3-bd2216804565",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count : 212\n",
      "Test Dataset Count : 89\n"
     ]
    }
   ],
   "source": [
    "# Create train/test split. Seed it for reproducibility.\n",
    "seed = 111\n",
    "train_df, test_df = car_df.randomSplit([0.7, 0.3], seed=seed)\n",
    "\n",
    "print('Training Dataset Count : {}'.format(train_df.count()))\n",
    "print('Test Dataset Count : {}'.format(test_df.count()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e20c5197-9486-4509-b6ca-5a1fb1860349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor_15b81f2ff96f"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a simlpe RandomForestRegressor model. This very simple model is meant \n",
    "# to show model feature inputs and outputs. The model is kept simple on purpose \n",
    "# to keep training time short.\n",
    "\n",
    "\n",
    "# For more information on model tuning and ParamGrid, \n",
    "# this is a good resource to start with : https://medium.com/rahasak/random-forest-classifier-with-apache-spark-c63b4a23a7cc\n",
    "\n",
    "# Instantiate RandomForestRegressor class\n",
    "rf = RandomForestRegressor(featuresCol='algorithmic_input', \n",
    "                           labelCol='Selling_Price'\n",
    ")\n",
    "\n",
    "# Set some parameters ...\n",
    "#\n",
    "# numTrees : Number of trees in the random forest.\n",
    "# maxDepth : Maximum depth of a tree. Increasing the depth makes the model more powerful, but deep trees take longer to train.\n",
    "# impurity : Criterion used for information gain calculation\n",
    "# setFeatureSubsetStrategy : auto -> Automatically select the number of features to consider for splits at each tree node\n",
    "# seed : Use a random seed number , allowing to repeat the results\n",
    "\n",
    "rf.setNumTrees(200)\n",
    "rf.setMaxDepth(20)\n",
    "rf.setImpurity(\"variance\")\n",
    "rf.setFeatureSubsetStrategy(\"auto\")\n",
    "rf.setSeed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31139a0c-5e41-4da2-9b44-2d7c531892ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/31 16:17:28 WARN DAGScheduler: Broadcasting large task binary with size 1361.6 KiB\n",
      "22/03/31 16:17:29 WARN DAGScheduler: Broadcasting large task binary with size 1952.2 KiB\n",
      "22/03/31 16:17:29 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "22/03/31 16:17:30 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "22/03/31 16:17:31 WARN DAGScheduler: Broadcasting large task binary with size 3.5 MiB\n",
      "22/03/31 16:17:32 WARN DAGScheduler: Broadcasting large task binary with size 3.8 MiB\n",
      "22/03/31 16:17:32 WARN DAGScheduler: Broadcasting large task binary with size 3.3 MiB\n",
      "22/03/31 16:17:33 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "22/03/31 16:17:33 WARN DAGScheduler: Broadcasting large task binary with size 1456.1 KiB\n"
     ]
    }
   ],
   "source": [
    "# Chain rf model in a Pipeline. Could have included previous steps above (indexer, encoder, assembler) ...\n",
    "pipeline = Pipeline(stages=[rf])\n",
    "\n",
    "# Train model\n",
    "model = pipeline.fit(train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61e46720-1402-4d8d-9476-9f873327fdf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------+-------------------+-------------+\n",
      "|algorithmic_input                     |prediction         |Selling_Price|\n",
      "+--------------------------------------+-------------------+-------------+\n",
      "|[0.47,21000.0,0.0,9.0,1.0,0.0,0.0,1.0]|0.33882113444809425|0.27         |\n",
      "|[0.74,5000.0,0.0,7.0,1.0,0.0,0.0,1.0] |0.5792188833732439 |0.65         |\n",
      "|[0.99,45000.0,0.0,9.0,1.0,0.0,0.0,1.0]|0.518399004410532  |0.5          |\n",
      "|[6.8,33019.0,0.0,8.0,1.0,0.0,1.0,1.0] |4.1583864987559815 |3.75         |\n",
      "|[5.8,40023.0,0.0,7.0,1.0,0.0,1.0,1.0] |4.57722290710424   |4.0          |\n",
      "+--------------------------------------+-------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions.\n",
    "\n",
    "predictions = model.transform(test_df)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"algorithmic_input\", \"prediction\", \"Selling_Price\").show(5, False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efe9833-d9d4-4030-9d1b-af60bd71a782",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c36f02c3-f79b-4cf6-9df0-c16ff8074dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 1.7682\n",
      "R Squared (R2) on test data = 0.879918\n",
      "Mean Absolute Error (MAE) on test data = 0.858415\n",
      "Mean Square Error (MSE) on test data = 3.12654\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Model.\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(labelCol=\"Selling_Price\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"Selling_Price\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "r2 = evaluator.evaluate(predictions)\n",
    "print(\"R Squared (R2) on test data = %g\" % r2)\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"Selling_Price\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "mae = evaluator.evaluate(predictions)\n",
    "print(\"Mean Absolute Error (MAE) on test data = %g\" % mae)\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"Selling_Price\", predictionCol=\"prediction\", metricName=\"mse\")\n",
    "mse = evaluator.evaluate(predictions)\n",
    "print(\"Mean Square Error (MSE) on test data = %g\" % mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74892fd-7106-4f19-aeea-4e1e17da3094",
   "metadata": {},
   "source": [
    "# Persist Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc982d70-fc36-48a7-ad6b-3a3c42dc5d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "# Overwriting to avoid errors in running notebook multiple times..\n",
    "model.write().overwrite().save('/data/rf.mdl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bd4f71-d00e-44b9-b051-a9cfacd3d497",
   "metadata": {},
   "source": [
    "# Load Saved Model and Score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d4fb9fb-3df2-4a8e-b195-49eeb3bc8d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "persisted_model = PipelineModel.load('/data/rf.mdl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09e778c0-902f-4ad8-9d8a-fbf0b2667232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input dataframe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------------------------------------------+\n",
      "|Selling_Price|algorithmic_input                                   |\n",
      "+-------------+----------------------------------------------------+\n",
      "|0.27         |[0.4699999988079071,21000.0,0.0,9.0,1.0,0.0,0.0,1.0]|\n",
      "+-------------+----------------------------------------------------+\n",
      "\n",
      "\n",
      "The predictions dataframe\n",
      "+----------------------------------------------------+-------------------+-------------+\n",
      "|algorithmic_input                                   |prediction         |Selling_Price|\n",
      "+----------------------------------------------------+-------------------+-------------+\n",
      "|[0.4699999988079071,21000.0,0.0,9.0,1.0,0.0,0.0,1.0]|0.33882113444809425|0.27         |\n",
      "+----------------------------------------------------+-------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "to_predict_schema = T.StructType([\n",
    "    T.StructField('Selling_Price', T.DoubleType(), False),\n",
    "    T.StructField('values_array', T.ArrayType(T.FloatType()), False)\n",
    "])\n",
    "\n",
    "to_predict_data = [\n",
    "    (0.27, [0.47,21000.0,0.0,9.0,1.0,0.0,0.0,1.0]),\n",
    "]\n",
    "\n",
    "to_predict_df = spark.createDataFrame(data=to_predict_data, schema=to_predict_schema)\n",
    "to_predict_df = to_predict_df.drop('algorithmic_input')\n",
    "\n",
    "# UDF to convert values_array into a VectorUDT. \n",
    "# VectorUDT is what is required to call the model for prediction. \n",
    "list_to_vector_udf = F.udf(lambda l: Vectors.dense(l), VectorUDT())\n",
    "\n",
    "\n",
    "to_predict_df = to_predict_df.select(\n",
    "    to_predict_df[\"Selling_Price\"], \n",
    "    list_to_vector_udf(to_predict_df[\"values_array\"]).alias(\"algorithmic_input\")\n",
    ")\n",
    "\n",
    "print('The input dataframe')\n",
    "to_predict_df.show(10, False)\n",
    "\n",
    "predictions = model.transform(to_predict_df)\n",
    "\n",
    "print()\n",
    "print('The predictions dataframe')\n",
    "predictions.select(\"algorithmic_input\", \"prediction\", \"Selling_Price\").show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3668c1c6-c979-445b-a0a4-92b12dc6fe5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c68eb2b-5043-4471-b52c-1ecaf261b9b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
