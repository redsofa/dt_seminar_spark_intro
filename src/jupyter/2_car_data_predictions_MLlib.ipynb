{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c207511-0fe4-4633-9124-a5c3fe025b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.linalg import Vectors, SparseVector\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import VectorUDT\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.pipeline import PipelineModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a1a112-53c6-4cc9-9b71-16857bc2d16d",
   "metadata": {},
   "source": [
    "# Start Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812212bf-65bd-488d-a5c1-dea4ec3550a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start spark session. \n",
    "\n",
    "spark = SparkSession\\\n",
    "            .builder\\\n",
    "            .master(\"spark://spark-master:7077\")\\\n",
    "            .appName(\"2_car_data_predictions_MLlib_jupyter\")\\\n",
    "            .config(\"spark.executor.memory\", \"3G\")\\\n",
    "            .config(\"spark.driver.memory\", \"3G\")\\\n",
    "            .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\\\n",
    "            .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5025afb-2a82-4882-adee-8b111d4c9d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the Spark session configuration. \n",
    "\n",
    "print(\"Spark Session configuration : \")\n",
    "\n",
    "print('===')\n",
    "\n",
    "for e in spark.sparkContext.getConf().getAll():\n",
    "    print(e)\n",
    "\n",
    "print('===')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c29feba-ff38-4676-af6c-7baccd98a0dd",
   "metadata": {},
   "source": [
    "# Load the Pre-processed Car Data Parquet File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865507a3-0400-48b9-84d8-3a7afaca1f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Parquet file.\n",
    "\n",
    "car_df = spark.read.parquet(\"/data/car_data.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8623d387-10c3-4bc4-b5da-b557b8ec3149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parquet files maintain the schema along with the data.\n",
    "# Print the dataframe schema. \n",
    "\n",
    "car_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3334550-1c32-4b26-810f-54648b259ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a few sample records. \n",
    "\n",
    "car_df.show(5, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425544e0-7e82-43a2-9f37-5d852eaf83e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's the partitioning situation in the Parquet file ?\n",
    "\n",
    "car_df\\\n",
    "    .withColumn(\"partitionId\", F.spark_partition_id())\\\n",
    "    .groupBy(\"partitionId\")\\\n",
    "    .count()\\\n",
    "    .orderBy(F.asc(\"count\"))\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174cbcd0-7e45-45fb-bb4a-de348f8a6d21",
   "metadata": {},
   "source": [
    "# Prepare Data for Algorithmic Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132928f4-8f61-4212-a33d-a59ef9fb09e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map a string column of labels to an ML column of label indices \n",
    "\n",
    "# (Colums : 'Fuel_Type', 'Seller_Type', 'Transmission').\n",
    "\n",
    "\n",
    "car_df = car_df.drop('fuel_Type_idx', 'seller_type_idx', 'transmission_idx')\n",
    "\n",
    "indexer = StringIndexer(inputCols=['Fuel_Type', 'Seller_Type', 'Transmission'],\n",
    "                        outputCols=['fuel_Type_idx', 'seller_type_idx', 'transmission_idx']\n",
    ")\n",
    "\n",
    "car_df = indexer.fit(car_df).transform(car_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763d3d8d-fa2c-41d1-bf06-2d4adc1d31ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We created 3 new columns. Show aggregate counts.\n",
    "\n",
    "car_df.select('Fuel_Type','fuel_Type_idx')\\\n",
    "    .groupBy('Fuel_Type','fuel_Type_idx')\\\n",
    "    .count()\\\n",
    "    .orderBy(F.col('fuel_Type_idx').asc())\\\n",
    "    .show()\n",
    "\n",
    "car_df.select('Seller_Type','seller_type_idx')\\\n",
    "    .groupBy('Seller_Type','seller_type_idx')\\\n",
    "    .count()\\\n",
    "    .orderBy(F.col('seller_type_idx').asc())\\\n",
    "    .show()\n",
    "\n",
    "car_df.select('Transmission','transmission_idx')\\\n",
    "    .groupBy('Transmission','transmission_idx')\\\n",
    "    .count()\\\n",
    "    .orderBy(F.col('transmission_idx').asc())\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db876bcb-a88a-4f4e-a342-57221aaf885f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The car_df dataframe will show the 3 extra columns : 'fuel_Type_idx', 'seller_type_idx', 'transmission_idx'\n",
    "\n",
    "car_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b236d96f-f3b4-40bb-8a49-8d1c3c3ecab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding. For string type input data, it is common to \n",
    "# encode categorical features using StringIndexer first.\n",
    "\n",
    "# Drop the columns I'm just about to create if they exist.\n",
    "car_df = car_df.drop('fuel_Type_vec', 'seller_type_vec', 'transmission_vec')\n",
    "\n",
    "encoder = OneHotEncoder(inputCols=['fuel_Type_idx', 'seller_type_idx', 'transmission_idx'],\n",
    "                        outputCols=['fuel_Type_vec', 'seller_type_vec', 'transmission_vec'],\n",
    "                        dropLast=True\n",
    ")\n",
    "model = encoder.fit(car_df)\n",
    "car_df = model.transform(car_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32a4074-6539-48bf-9128-40a88eed26dc",
   "metadata": {},
   "source": [
    "# Visual One Hot encoding ? \n",
    "\n",
    "<img src=\"media/one_hot.png\" alt=\"one_hot\" width=\"800\"/>\n",
    "\n",
    "Image Source : https://medium.com/@michaeldelsole/what-is-one-hot-encoding-and-how-to-do-it-f0ae272f1179"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac88d45-edf1-4ea0-b875-b1fc6aaf1413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Something to be aware of ...\n",
    "\n",
    "# PySpark automatically drops the last category is not included BY DEFAULT. This is to avoid a Dummy Variable Trap\n",
    "# linear regression models....\n",
    "\n",
    "# What is the Dummy Variable Trap (DVT)? The DVT occurs when two or more dummy variables \n",
    "# created by one-hot encoding are highly correlated (multi-collinear). This means that one variable can be \n",
    "# predicted from the others, making it difficult to interpret predicted coefficient variables in regression models.\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/39500213/why-does-sparks-onehotencoder-drop-the-last-category-by-default\n",
    "\n",
    "# But basically, ... dropping the last cat. value is done to avoid a DVT where one input variable can be predicted \n",
    "# from the others (eg. don't need a 1hot encoding of [isBoy, isGirl] when an encoding [isBoy] would give the same info). \n",
    "# The solution to the DVT is to drop one (not necessarily the last) of the cat. variables.\n",
    "\n",
    "\n",
    "# There are 3 fuel types but the 'fuel_type_vec' column has only 2 elements because of this DVT last category drop thing.\n",
    "\n",
    "# https://spark.apache.org/docs/latest/ml-features.html#vectorassembler\n",
    "\n",
    "# Reminder... sparse vector (size, [non-zero indices], [non-zero values]) \n",
    "# [1.0,0.0] = (2,[0],[1.0]) - > (vector of size 2, [index 0], [gets value 1.0])\n",
    "\n",
    "car_df\\\n",
    "    .select('Fuel_type', 'fuel_type_idx', 'fuel_type_vec')\\\n",
    "    .distinct()\\\n",
    "    .show(10)\n",
    "                                                                                                                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3da80d-1701-4d44-bb65-058d3b2c47ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the car_df schema. \n",
    "\n",
    "# The car_df dataframe will show the 3 extra columns : 'fuel_Type_vec', 'seller_type_vec', 'transmission_vec'\n",
    "\n",
    "car_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7e8dd4-907f-4fe2-bd7d-7e4d01d9d5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the column if exists\n",
    "car_df = car_df.drop('algorithmic_input')\n",
    "\n",
    "\n",
    "# Assemble features I'm interested in using as a large vector column called 'algorithmic_input'.\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\n",
    "        'Present_Price', \n",
    "        'Kms_Driven', \n",
    "        'Owner', \n",
    "        'Car_Age', \n",
    "        'fuel_Type_vec', \n",
    "        'seller_type_vec',\n",
    "        'transmission_vec'\n",
    "    ],\n",
    "    outputCol='algorithmic_input')\n",
    "\n",
    "\n",
    "car_df = assembler.transform(car_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca1cc86-8e8f-4af0-b6b6-49c94ca4a2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the car_df schema. \n",
    "\n",
    "# The car_df dataframe will show the 1 extra columns : 'algorithmic_input'\n",
    "\n",
    "car_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918014d0-b50a-46d1-a4f7-7ffcec903c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the some of the table columns\n",
    "\n",
    "car_df.select('algorithmic_input', 'Selling_Price').show(10, False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25713e58-1a13-4a93-a3a6-2af5a2fc8193",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52917ba-fc9e-458d-bcd3-bd2216804565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/test split. Seed it for reproducibility.\n",
    "seed = 111\n",
    "train_df, test_df = car_df.randomSplit([0.7, 0.3], seed=seed)\n",
    "\n",
    "print('Training Dataset Count : {}'.format(train_df.count()))\n",
    "print('Test Dataset Count : {}'.format(test_df.count()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20c5197-9486-4509-b6ca-5a1fb1860349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a simlpe RandomForestRegressor model. This very simple model is meant \n",
    "# to show model feature inputs and outputs. The model is kept simple on purpose \n",
    "# to keep training time short.\n",
    "\n",
    "\n",
    "# For more information on model tuning and ParamGrid, \n",
    "# this is a good resource to start with : https://medium.com/rahasak/random-forest-classifier-with-apache-spark-c63b4a23a7cc\n",
    "\n",
    "# Instantiate RandomForestRegressor class\n",
    "rf = RandomForestRegressor(featuresCol='algorithmic_input', \n",
    "                           labelCol='Selling_Price'\n",
    ")\n",
    "\n",
    "# Set some parameters ...\n",
    "#\n",
    "# numTrees : Number of trees in the random forest.\n",
    "# maxDepth : Maximum depth of a tree. Increasing the depth makes the model more powerful, but deep trees take longer to train.\n",
    "# impurity : Criterion used for information gain calculation\n",
    "# setFeatureSubsetStrategy : auto -> Automatically select the number of features to consider for splits at each tree node\n",
    "# seed : Use a random seed number , allowing to repeat the results\n",
    "\n",
    "rf.setNumTrees(200)\n",
    "rf.setMaxDepth(20)\n",
    "rf.setImpurity(\"variance\")\n",
    "rf.setFeatureSubsetStrategy(\"auto\")\n",
    "rf.setSeed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31139a0c-5e41-4da2-9b44-2d7c531892ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain rf model in a Pipeline. Could have included previous steps above (indexer, encoder, assembler) ...\n",
    "pipeline = Pipeline(stages=[rf])\n",
    "\n",
    "# Train model\n",
    "model = pipeline.fit(train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e46720-1402-4d8d-9476-9f873327fdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions.\n",
    "\n",
    "predictions = model.transform(test_df)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"algorithmic_input\", \"prediction\", \"Selling_Price\").show(5, False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efe9833-d9d4-4030-9d1b-af60bd71a782",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36f02c3-f79b-4cf6-9df0-c16ff8074dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model.\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(labelCol=\"Selling_Price\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"Selling_Price\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "r2 = evaluator.evaluate(predictions)\n",
    "print(\"R Squared (R2) on test data = %g\" % r2)\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"Selling_Price\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "mae = evaluator.evaluate(predictions)\n",
    "print(\"Mean Absolute Error (MAE) on test data = %g\" % mae)\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"Selling_Price\", predictionCol=\"prediction\", metricName=\"mse\")\n",
    "mse = evaluator.evaluate(predictions)\n",
    "print(\"Mean Square Error (MSE) on test data = %g\" % mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74892fd-7106-4f19-aeea-4e1e17da3094",
   "metadata": {},
   "source": [
    "# Persist Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc982d70-fc36-48a7-ad6b-3a3c42dc5d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Overwriting to avoid errors in running notebook multiple times..\n",
    "model.write().overwrite().save('/data/rf.mdl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bd4f71-d00e-44b9-b051-a9cfacd3d497",
   "metadata": {},
   "source": [
    "# Load Saved Model and Score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4fb9fb-3df2-4a8e-b195-49eeb3bc8d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "persisted_model = PipelineModel.load('/data/rf.mdl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e778c0-902f-4ad8-9d8a-fbf0b2667232",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_predict_schema = T.StructType([\n",
    "    T.StructField('Selling_Price', T.DoubleType(), False),\n",
    "    T.StructField('values_array', T.ArrayType(T.FloatType()), False)\n",
    "])\n",
    "\n",
    "to_predict_data = [\n",
    "    (0.27, [0.47,21000.0,0.0,9.0,1.0,0.0,0.0,1.0]),\n",
    "]\n",
    "\n",
    "to_predict_df = spark.createDataFrame(data=to_predict_data, schema=to_predict_schema)\n",
    "to_predict_df = to_predict_df.drop('algorithmic_input')\n",
    "\n",
    "# UDF to convert values_array into a VectorUDT. \n",
    "# VectorUDT is what is required to call the model for prediction. \n",
    "list_to_vector_udf = F.udf(lambda l: Vectors.dense(l), VectorUDT())\n",
    "\n",
    "\n",
    "to_predict_df = to_predict_df.select(\n",
    "    to_predict_df[\"Selling_Price\"], \n",
    "    list_to_vector_udf(to_predict_df[\"values_array\"]).alias(\"algorithmic_input\")\n",
    ")\n",
    "\n",
    "print('The input dataframe')\n",
    "to_predict_df.show(10, False)\n",
    "\n",
    "predictions = persisted_model.transform(to_predict_df)\n",
    "\n",
    "print()\n",
    "print('The predictions dataframe')\n",
    "predictions.select(\"algorithmic_input\", \"prediction\", \"Selling_Price\").show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3668c1c6-c979-445b-a0a4-92b12dc6fe5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c68eb2b-5043-4471-b52c-1ecaf261b9b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
