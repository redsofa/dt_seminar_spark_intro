{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c207511-0fe4-4633-9124-a5c3fe025b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a1a112-53c6-4cc9-9b71-16857bc2d16d",
   "metadata": {},
   "source": [
    "# Start Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25188f97-84f6-46ac-b9ef-943134094344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default, Spark’s standalone scheduler runs jobs in FIFO fashion. \n",
    "# The first job gets priority on all available resources, then the second job gets priority, etc. \n",
    "\n",
    "# If the jobs at the head of the queue don’t need to use the whole cluster, later jobs can start to \n",
    "# run right away, but if the jobs at the head of the queue are large, then later jobs may be delayed significantly.\n",
    "\n",
    "# It is also possible to configure fair sharing between jobs.\n",
    "\n",
    "# More info here : https://spark.apache.org/docs/latest/job-scheduling.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "812212bf-65bd-488d-a5c1-dea4ec3550a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/01 14:32:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "# Start spark session. Not specifying what we want for executor and core resources, gets us all available resources.\n",
    "# Default for 'spark.executor.memory' (memory per worker) is 1GB. Need to bump that up explicitely, if we want more.\n",
    "\n",
    "# Ask for too many resources, and your job sits waiting for these resources to become available.\n",
    "# You'll get warnings asking you to check your cluster UI to ensure that workers are registered and have sufficient resources.\n",
    "\n",
    "spark = SparkSession\\\n",
    "            .builder\\\n",
    "            .master('spark://spark-master:7077')\\\n",
    "            .appName('common_ops_jupyter')\\\n",
    "            .config('spark.jars', '/src/java/spark-jobs/helloworld/target/jv_helloworld-1.0-SNAPSHOT.jar')\\\n",
    "            .config('spark.executor.extraClassPath', '/src/java/spark-jobs/helloworld/target/jv_helloworld-1.0-SNAPSHOT.jar')\\\n",
    "            .config('spark.driver.memory', '2G')\\\n",
    "            .config('spark.executor.memory', '3G')\\\n",
    "            .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb1d0c91-a370-4b18-ae04-997db729062c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add jar to java spark context. It has a UDF that I want to use later.\n",
    "\n",
    "spark._jsc.addJar(\"/src/java/spark-jobs/helloworld/target/jv_helloworld-1.0-SNAPSHOT.jar\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cca2f4f-b20e-433d-862a-72db4464b8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the java function. It will be available as StringLengthUDF (in the spark.sql command).\n",
    "\n",
    "spark.udf.registerJavaFunction(\"StringLengthUDF\", \"ca.nrc.udf.StringLengthUDF\", T.LongType())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c29feba-ff38-4676-af6c-7baccd98a0dd",
   "metadata": {},
   "source": [
    "# Create Some Toy Data - (The Person and Vehicle Relationship)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dae3e5d-f077-422a-bfea-2bd1c4a917b6",
   "metadata": {},
   "source": [
    "![erd](media/erd.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e249ac-5ec5-4c33-a979-e34dc2cf68e8",
   "metadata": {},
   "source": [
    "# The Person Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a671b61-12ad-4383-962d-16737edbb6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Person Table\n",
    "\n",
    "person_schema = T.StructType([\n",
    "    T.StructField('person_id', T.StringType(), False),\n",
    "    T.StructField('first_name',T.StringType(), False),\n",
    "    T.StructField('last_name',T.StringType(), False),\n",
    "    T.StructField('gender', T.StringType(), False),\n",
    "    T.StructField('date_of_birth', T.DateType(), False),\n",
    "    T.StructField('children_ages', T.ArrayType(T.IntegerType()), False)\n",
    "])\n",
    "\n",
    "person_data = [\n",
    "    ('001','Willy','Walker', 'M', datetime.date(1971, 3, 18), [21, 23]),\n",
    "    ('002','Marry','Brown', 'F', datetime.date(1974, 3, 19), [4, 11, 15]),\n",
    "    ('003','Harry','Snow', 'M', datetime.date(1965, 3, 20), [23, 25]),\n",
    "    ('004','Joey','Jollymore', 'M', datetime.date(1971, 3, 13), [12, 15, 17]),\n",
    "    ('005','Tim','Horton', 'M', datetime.date(1963, 3, 14), [11, 15]),\n",
    "    ('006','Jenny','Purple', 'F', datetime.date(1971, 3, 14), [14, 18, 21]),\n",
    "    ('007','Ronald','McDonald', 'M', datetime.date(1972, 3, 14), [11, 15]),\n",
    "    ('008','Oscar','Grouch', 'M', datetime.date(1968, 3, 14), [20, 22]),\n",
    "    ('009','Kermit','Frog', 'M', datetime.date(1969, 3, 14), [19, 25]),\n",
    "    ('010','Anna','Green', 'F', datetime.date(1973, 3, 14), [13, 15]),\n",
    "]\n",
    "\n",
    "person_df = spark.createDataFrame(data=person_data, schema=person_schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "865507a3-0400-48b9-84d8-3a7afaca1f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- person_id: string (nullable = false)\n",
      " |-- first_name: string (nullable = false)\n",
      " |-- last_name: string (nullable = false)\n",
      " |-- gender: string (nullable = false)\n",
      " |-- date_of_birth: date (nullable = false)\n",
      " |-- children_ages: array (nullable = false)\n",
      " |    |-- element: integer (containsNull = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+---------+------+-------------+-------------+\n",
      "|person_id|first_name|last_name|gender|date_of_birth|children_ages|\n",
      "+---------+----------+---------+------+-------------+-------------+\n",
      "|001      |Willy     |Walker   |M     |1971-03-18   |[21, 23]     |\n",
      "|002      |Marry     |Brown    |F     |1974-03-19   |[4, 11, 15]  |\n",
      "|003      |Harry     |Snow     |M     |1965-03-20   |[23, 25]     |\n",
      "|004      |Joey      |Jollymore|M     |1971-03-13   |[12, 15, 17] |\n",
      "|005      |Tim       |Horton   |M     |1963-03-14   |[11, 15]     |\n",
      "|006      |Jenny     |Purple   |F     |1971-03-14   |[14, 18, 21] |\n",
      "|007      |Ronald    |McDonald |M     |1972-03-14   |[11, 15]     |\n",
      "|008      |Oscar     |Grouch   |M     |1968-03-14   |[20, 22]     |\n",
      "|009      |Kermit    |Frog     |M     |1969-03-14   |[19, 25]     |\n",
      "|010      |Anna      |Green    |F     |1973-03-14   |[13, 15]     |\n",
      "+---------+----------+---------+------+-------------+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "# This data is mostly tabular in format.  \n",
    "# There is a slightly more complex structure for the children_age field (ArrayType).\n",
    "\n",
    "# Spark can deal with different file formats (json, avro, orc, etc..) \n",
    "# and has utilities to manupulate complext types (e.g. Exploding the nested structure into individual rows etc).\n",
    "\n",
    "person_df.printSchema()\n",
    "person_df.show(10, False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6910ff7a-a866-485c-85a4-3cc26aea3179",
   "metadata": {},
   "source": [
    "# The Vehicle Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7571493-7594-483f-b125-e78ec9cd3873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Vehicle Table\n",
    "\n",
    "vehicle_schema = T.StructType([\n",
    "    T.StructField('person_id', T.StringType(), False),\n",
    "    T.StructField('vehicle_id', T.StringType(), False),\n",
    "    T.StructField('vehicle_name', T.StringType(), False),\n",
    "])\n",
    "\n",
    "vehicle_data = [\n",
    "    ('001','v-001','Honda Civic'),\n",
    "    ('001','v-002','Honda Fit'),\n",
    "    ('001','v-003','Honda Ruckus'),\n",
    "    ('001','v-004','Toyota Camry'),\n",
    "    ('002','v-005','Toyota Camry'),\n",
    "    ('002','v-005','Toyota Rav4'),\n",
    "    ('002','v-010','Geo Metro'),    \n",
    "    ('005','v-006','Doge Caravan'),\n",
    "    ('005','v-007','Toyota Camry'),\n",
    "    ('007','v-008','Honda Civic'),\n",
    "    ('010','v-009','Honda Civic'),\n",
    "]\n",
    "\n",
    "vehicle_df = spark.createDataFrame(data=vehicle_data, schema=vehicle_schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3508054c-b682-4783-b3cd-b30adc2ecf14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- person_id: string (nullable = false)\n",
      " |-- vehicle_id: string (nullable = false)\n",
      " |-- vehicle_name: string (nullable = false)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+------------+\n",
      "|person_id|vehicle_id|vehicle_name|\n",
      "+---------+----------+------------+\n",
      "|001      |v-001     |Honda Civic |\n",
      "|001      |v-002     |Honda Fit   |\n",
      "|001      |v-003     |Honda Ruckus|\n",
      "|001      |v-004     |Toyota Camry|\n",
      "|002      |v-005     |Toyota Camry|\n",
      "|002      |v-005     |Toyota Rav4 |\n",
      "|002      |v-010     |Geo Metro   |\n",
      "|005      |v-006     |Doge Caravan|\n",
      "|005      |v-007     |Toyota Camry|\n",
      "|007      |v-008     |Honda Civic |\n",
      "+---------+----------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print schema and some sample data for the vehicle dataframe.\n",
    "\n",
    "vehicle_df.printSchema()\n",
    "vehicle_df.show(10, False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b13a6c-bcf6-4f71-8dc7-951d547fb5cf",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "805b90c9-612b-4ce2-9d4c-4077d62c11f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lifted from : https://stackoverflow.com/questions/2217488/age-from-birthdate-in-python\n",
    "\n",
    "# Function to calculate your age in years. Input is the date of birth.\n",
    "def calculate_age(date_born):\n",
    "    today = datetime.date.today()\n",
    "    return today.year - date_born.year - ((today.month, today.day) < (date_born.month, date_born.day))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b95274d2-e0b6-4318-afef-69e097a069fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a user defined function... a.k.a a UDF (i.e. a user-programmable routine that act on one row).\n",
    "\n",
    "calc_age_udf = F.udf(lambda date_born: calculate_age(date_born), T.IntegerType())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ca1cc86-8e8f-4af0-b6b6-49c94ca4a2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add person_age field by calling a Python UDF\n",
    "person_df = person_df.withColumn('person_age', calc_age_udf(F.col('date_of_birth')))\n",
    "\n",
    "# Add birth day of week field (birth_dow) by calling PySpark canned utily function\n",
    "person_df = person_df.withColumn('birth_dow', F.dayofweek('date_of_birth'))\n",
    "\n",
    "# Add the first name length field (fname_length) by calling a Java function. \n",
    "# This function lives in the jar we added to Spark earlier.\n",
    "person_df = person_df.withColumn(\"fname_length\", F.expr(\"StringLengthUDF(first_name)\"))                                 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "918014d0-b50a-46d1-a4f7-7ffcec903c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+---------+------+-------------+-------------+----------+---------+------------+\n",
      "|person_id|first_name|last_name|gender|date_of_birth|children_ages|person_age|birth_dow|fname_length|\n",
      "+---------+----------+---------+------+-------------+-------------+----------+---------+------------+\n",
      "|001      |Willy     |Walker   |M     |1971-03-18   |[21, 23]     |51        |5        |5           |\n",
      "|002      |Marry     |Brown    |F     |1974-03-19   |[4, 11, 15]  |48        |3        |5           |\n",
      "|003      |Harry     |Snow     |M     |1965-03-20   |[23, 25]     |57        |7        |5           |\n",
      "|004      |Joey      |Jollymore|M     |1971-03-13   |[12, 15, 17] |51        |7        |4           |\n",
      "|005      |Tim       |Horton   |M     |1963-03-14   |[11, 15]     |59        |5        |3           |\n",
      "|006      |Jenny     |Purple   |F     |1971-03-14   |[14, 18, 21] |51        |1        |5           |\n",
      "|007      |Ronald    |McDonald |M     |1972-03-14   |[11, 15]     |50        |3        |6           |\n",
      "|008      |Oscar     |Grouch   |M     |1968-03-14   |[20, 22]     |54        |5        |5           |\n",
      "|009      |Kermit    |Frog     |M     |1969-03-14   |[19, 25]     |53        |6        |6           |\n",
      "|010      |Anna      |Green    |F     |1973-03-14   |[13, 15]     |49        |4        |4           |\n",
      "+---------+----------+---------+------+-------------+-------------+----------+---------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Show the transformed dataframe. \n",
    "# We should see the newly created columns : [person_age, birth_dow, fname_length]\n",
    "\n",
    "person_df.show(10, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e52917ba-fc9e-458d-bcd3-bd2216804565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(i_list)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do some transformations with SparkSQL.\n",
    "\n",
    "# Create fucntion to calculate max from list.\n",
    "def max_age(i_list):\n",
    "    return max(i_list)\n",
    "\n",
    "# Create a user defined function (i.e. a user-programmable routine that act on one row).\n",
    "max_age_udf = F.udf(lambda i_list: max_age(i_list), T.IntegerType())\n",
    "\n",
    "# Need to register UDF if we want to use it with spark.sql command\n",
    "spark.udf.register(\"max_age_udf\", max_age_udf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa101b9e-6de5-4fc8-9e21-145b7ad5b075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary table where lifetime is tied to the SparkSession\n",
    "\n",
    "person_df.createOrReplaceTempView(\"PERSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc982d70-fc36-48a7-ad6b-3a3c42dc5d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a colum called eldest_child_age in the person_df dataframe. \n",
    "# Do this using Spark's SQL interface.\n",
    "\n",
    "sql_str = '''SELECT \n",
    "                *, \n",
    "                max_age_udf(children_ages) as eldest_child_age\n",
    "            FROM \n",
    "                PERSON'''\n",
    "\n",
    "person_df = spark.sql(sql_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09e778c0-902f-4ad8-9d8a-fbf0b2667232",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+---------+------+-------------+-------------+----------+---------+------------+----------------+\n",
      "|person_id|first_name|last_name|gender|date_of_birth|children_ages|person_age|birth_dow|fname_length|eldest_child_age|\n",
      "+---------+----------+---------+------+-------------+-------------+----------+---------+------------+----------------+\n",
      "|001      |Willy     |Walker   |M     |1971-03-18   |[21, 23]     |51        |5        |5           |23              |\n",
      "|002      |Marry     |Brown    |F     |1974-03-19   |[4, 11, 15]  |48        |3        |5           |15              |\n",
      "|003      |Harry     |Snow     |M     |1965-03-20   |[23, 25]     |57        |7        |5           |25              |\n",
      "|004      |Joey      |Jollymore|M     |1971-03-13   |[12, 15, 17] |51        |7        |4           |17              |\n",
      "|005      |Tim       |Horton   |M     |1963-03-14   |[11, 15]     |59        |5        |3           |15              |\n",
      "|006      |Jenny     |Purple   |F     |1971-03-14   |[14, 18, 21] |51        |1        |5           |21              |\n",
      "|007      |Ronald    |McDonald |M     |1972-03-14   |[11, 15]     |50        |3        |6           |15              |\n",
      "|008      |Oscar     |Grouch   |M     |1968-03-14   |[20, 22]     |54        |5        |5           |22              |\n",
      "|009      |Kermit    |Frog     |M     |1969-03-14   |[19, 25]     |53        |6        |6           |25              |\n",
      "|010      |Anna      |Green    |F     |1973-03-14   |[13, 15]     |49        |4        |4           |15              |\n",
      "+---------+----------+---------+------+-------------+-------------+----------+---------+------------+----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "# Show the transformed dataframe. \n",
    "# We should see the newly created column : [eldest_child_age]\n",
    "\n",
    "person_df.show(10, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be3476c4-c64c-4a4d-9798-59157502d047",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create vehicle_count Column - (Aggregation and Joinning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53bbf7a0-d3cd-4d23-8a93-b3624f98273a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+\n",
      "|person_id|vehicle_count|\n",
      "+---------+-------------+\n",
      "|      001|            4|\n",
      "|      005|            2|\n",
      "|      002|            3|\n",
      "|      010|            1|\n",
      "|      007|            1|\n",
      "+---------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Need list of person_ids and their vehicle counts.\n",
    "# Example of aggregation. Can do sums, min, max etc. \n",
    "# Many aggregations included in API.\n",
    "\n",
    "person_vehicle_count_df = vehicle_df\\\n",
    "    .select('person_id', 'vehicle_id')\\\n",
    "    .groupBy('person_id')\\\n",
    "    .count()\\\n",
    "    .withColumnRenamed('count', 'vehicle_count')\\\n",
    "\n",
    "person_vehicle_count_df\\\n",
    "    .show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21147309-9ce7-40f3-93b7-b028e53bcc8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+---------+------+-------------+-------------+----------+---------+------------+----------------+-------------+\n",
      "|person_id|first_name|last_name|gender|date_of_birth|children_ages|person_age|birth_dow|fname_length|eldest_child_age|vehicle_count|\n",
      "+---------+----------+---------+------+-------------+-------------+----------+---------+------------+----------------+-------------+\n",
      "|      001|     Willy|   Walker|     M|   1971-03-18|     [21, 23]|        51|        5|           5|              23|            4|\n",
      "|      002|     Marry|    Brown|     F|   1974-03-19|  [4, 11, 15]|        48|        3|           5|              15|            3|\n",
      "|      003|     Harry|     Snow|     M|   1965-03-20|     [23, 25]|        57|        7|           5|              25|            0|\n",
      "|      004|      Joey|Jollymore|     M|   1971-03-13| [12, 15, 17]|        51|        7|           4|              17|            0|\n",
      "|      005|       Tim|   Horton|     M|   1963-03-14|     [11, 15]|        59|        5|           3|              15|            2|\n",
      "|      006|     Jenny|   Purple|     F|   1971-03-14| [14, 18, 21]|        51|        1|           5|              21|            0|\n",
      "|      007|    Ronald| McDonald|     M|   1972-03-14|     [11, 15]|        50|        3|           6|              15|            1|\n",
      "|      008|     Oscar|   Grouch|     M|   1968-03-14|     [20, 22]|        54|        5|           5|              22|            0|\n",
      "|      009|    Kermit|     Frog|     M|   1969-03-14|     [19, 25]|        53|        6|           6|              25|            0|\n",
      "|      010|      Anna|    Green|     F|   1973-03-14|     [13, 15]|        49|        4|           4|              15|            1|\n",
      "+---------+----------+---------+------+-------------+-------------+----------+---------+------------+----------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Join person_df and person_vehicle_count_df dataframes. \n",
    "# Need people with and without vehicles.\n",
    "\n",
    "person_and_cars_df = person_df\\\n",
    "    .join(person_vehicle_count_df, on=['person_id'], how='left_outer')\\\n",
    "    .withColumn(\"vehicle_count\", F.when(F.col('vehicle_count').isNotNull(), F.col('vehicle_count')).otherwise(F.lit(0)))\n",
    "\n",
    "\n",
    "person_and_cars_df\\\n",
    "    .orderBy('person_id', ascending=True)\\\n",
    "    .show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047bf705-e555-447b-8128-be3a7a1fb3ad",
   "metadata": {},
   "source": [
    "# Filtering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d74770a-9d94-4e66-adf0-0eb64dcf9d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------------+-------------+\n",
      "|person_id|person_name (last,first)|vehicle_count|\n",
      "+---------+------------------------+-------------+\n",
      "|      005|             Horton, Tim|            2|\n",
      "|      001|           Walker, Willy|            4|\n",
      "|      002|            Brown, Marry|            3|\n",
      "|      010|             Green, Anna|            1|\n",
      "|      007|        McDonald, Ronald|            1|\n",
      "+---------+------------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# People with more than 1 vehicle\n",
    "# Select person_id, name (format the name as : last, first) and the vehicle count\n",
    "\n",
    "person_and_cars_df\\\n",
    "    .select('person_id', \n",
    "            F.concat(F.col('last_name'), F.lit(', '), F.col('first_name')).alias('person_name (last,first)'),\n",
    "            'vehicle_count'\n",
    "    )\\\n",
    "    .filter(F.col('vehicle_count') >= 1).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba222252-6491-445a-b92b-21cc44fec0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------------+-------------+\n",
      "|person_id|person_name (last,first)|vehicle_count|\n",
      "+---------+------------------------+-------------+\n",
      "|      003|             Snow, Harry|            0|\n",
      "|      004|         Jollymore, Joey|            0|\n",
      "|      009|            Frog, Kermit|            0|\n",
      "|      006|           Purple, Jenny|            0|\n",
      "|      008|           Grouch, Oscar|            0|\n",
      "+---------+------------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# People who don't have a vehicle\n",
    "\n",
    "person_and_cars_df\\\n",
    "    .select('person_id', \n",
    "            F.concat(F.col('last_name'), F.lit(', '), F.col('first_name')).alias('person_name (last,first)'),\n",
    "            'vehicle_count'\n",
    "    )\\\n",
    "    .filter(F.col('vehicle_count') == 0).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f4d2bc-eea7-44d8-991c-c1a0c03bb5df",
   "metadata": {},
   "source": [
    "# Windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c6f725f-638c-48be-8452-44d0e12adfe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+---------+------+-------------+----+\n",
      "|person_id|first_name|last_name|gender|vehicle_count|rank|\n",
      "+---------+----------+---------+------+-------------+----+\n",
      "|      001|     Willy|   Walker|     M|            4|   1|\n",
      "|      005|       Tim|   Horton|     M|            2|   2|\n",
      "|      002|     Marry|    Brown|     F|            3|   1|\n",
      "|      010|      Anna|    Green|     F|            1|   2|\n",
      "+---------+----------+---------+------+-------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ref : https://databricks.com/blog/2015/07/15/introducing-window-functions-in-spark-sql.html\n",
    "\n",
    "\n",
    "# Windowing function enable us to both operate on a group of rows while still returning a single value for every input row. \n",
    "# With windowing, we can calculate moving averages, cumulative sums, or access the values of a row appearing before \n",
    "# the current row. \n",
    "\n",
    "# “Rank car owners by number of cars they own and their sex. What is the top 2 vehicle count in each gender category ?”\n",
    "\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "\n",
    "windowSpec = Window.partitionBy(F.col('gender')).orderBy(F.col('vehicle_count').desc())\n",
    "\n",
    "\n",
    "person_and_cars_df\\\n",
    "    .select('person_id', 'first_name', 'last_name', 'gender', 'vehicle_count')\\\n",
    "    .withColumn(\"rank\", F.rank().over(windowSpec)) \\\n",
    "    .orderBy(F.col('gender').desc(), F.col('rank').asc())\\\n",
    "    .filter(F.col('rank') <= 2)\\\n",
    "    .show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3668c1c6-c979-445b-a0a4-92b12dc6fe5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bb463e-af5c-4255-ab64-f2dc06b3491e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
